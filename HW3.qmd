---
title: "Homework Assignment 2: Identifying the impacts of extreme weather"
author: "Caitlin Nordheim-Maestas"
date: "`r Sys.Date()`"
format: html
---

<https://eds-223-geospatial.github.io/assignments/HW3.html>

# 0. Setup

## 0.1 read in data

```{r}
#| message: false
#| warning: false

library(tidyverse) # data wrangling
library(sf) # for spatial data
library(tmap) # for pretty maps
library(here) # file pathing
library(viridisLite) # colors
library(janitor) # data wrangling
library(kableExtra) # pretty table
library(patchwork) # combine plots
library(stars) # rasters
library(terra) # rasters

# load in data 

#..........................Night lights..........................
## read_stars for the raster data!!!
# can later read it back to a rast by wrapping your object around a rast rast(stars_object)
## VIIRS data

# tile 5 date 1
tile5_2.7 <- read_stars(here::here("data","VNP46A1", "VNP46A1.A2021038.h08v05.001.2021039064328.tif"),
               quiet = TRUE) # hide the message

# tile 6 date 1
tile6_2.7 <- read_stars(here::here("data","VNP46A1","VNP46A1.A2021038.h08v06.001.2021039064329.tif"),
               quiet = TRUE) # hide the message

# tile 5 date 2
tile5_2.16 <- read_stars(here::here("data","VNP46A1", "VNP46A1.A2021047.h08v05.001.2021048091106.tif"),
               quiet = TRUE) # hide the message

# tile 6 date 2
tile6_2.16 <- read_stars(here::here("data","VNP46A1", "VNP46A1.A2021047.h08v06.001.2021048091105.tif"),
               quiet = TRUE) # hide the message

#..............................Roads.............................

# roads: gis_osm_roads_free_1.gpkg
road <- st_read(here::here("data", "gis_osm_roads_free_1.gpkg"),
                # from homework tip, only load needed data
                query = "SELECT * FROM gis_osm_roads_free_1 WHERE fclass='motorway'", 
              quiet = TRUE) %>% # hide the message
  st_make_valid() 

#.............................Houses.............................

house <- st_read(here::here("data", "gis_osm_buildings_a_free_1.gpkg"),
                 # use SQL query to only read in data we need (given in the hw instructions)
                 # The buildings geopackage includes data on many types of buildings; 
                 # we can avoid reading in data we don’t need:
                 query = "SELECT *
                          FROM gis_osm_buildings_a_free_1 
                          WHERE (type IS NULL AND name IS NULL)
                          OR type in ('residential', 'apartments', 'house', 'static_caravan', 'detached')", 
              quiet = TRUE) %>% 
               st_make_valid()

#..........................Socioeconomic.........................

# Socioeconomic: folder ACS_2019_5YR_TRACT_48.gdb is an ArcGIS “file geodatabase”, a multi-file proprietary format that’s roughly analogous to a GeoPackage file

## use st_layers() to explore the contents of the geodatabase, because geodatabases has layers
# st_layers(here::here("data","ACS_2019_5YR_TRACT_48_TEXAS.gdb")) # takes a whole to run, long output, commented out
# important finds: X19_INCOME, TRACT_METADATA_2019, ACS_2019_5YR_TRACT_48_TEXAS

# geography layer
geo_layer <- st_read(here::here("data", "ACS_2019_5YR_TRACT_48_TEXAS.gdb"),
              layer = "ACS_2019_5YR_TRACT_48_TEXAS", # specify the layer to read in
               quiet = TRUE) %>% # no long message
               st_make_valid()

# income layer
income <- st_read(here::here("data", "ACS_2019_5YR_TRACT_48_TEXAS.gdb"),
              layer = "X19_INCOME", # specify the layer to read in for income (from exploration)
               quiet = TRUE) # no long message

# metadata (colnames)
meta <- st_read(here::here("data", "ACS_2019_5YR_TRACT_48_TEXAS.gdb"),
              layer = "TRACT_METADATA_2019", # specify the layer to read in for income (from exploration)
               quiet = TRUE)

# Hint: You have to combine the geometry with the attributes to get a feature layer that sf can use. I will do this in section 0.2

```

## 0.2 Let's explore the data

### Light at night explore & wrangle

These are raster files that show the light at night to explore the power outages. There are 2 "tiles" that encompass Houston, so I will combine those tiles to end up with `day1` and `day2` rasters for the whole Houston area.

A note about the rasters, I used `stars` to read in the data, so I will use `st_mosaic` to combine the rasters which are stars objects.

*This data also needs to be scaled according to the metadata, but in office hours, it seems like that should be done after masking?*

```{r}
# day 1 raster: combine tiles 5 and 6
d1_stars <- st_mosaic(tile5_2.7, tile6_2.7)
# day 1 raster: combine tiles 5 and 6
d2_stars <- st_mosaic(tile5_2.16, tile6_2.16)

# do the 2 extents match?
if(ext(alan_d1) == ext(alan_d2)){
  print("extents match")
} else{
  print("extents do not match")
} # "extents match" yay

# check crs
st_crs(alan_d1) # WGS84
st_crs(alan_d2) # WGS84

# quick vis
# m1 <- tm_shape(d1_stars) + 
#   tm_raster(col.legend = tm_legend(title = "ALAN"))+ # use color legend
#   tm_graticules()+ # orienting
#   tm_title(text = "day 1 stars") # title
# 
# m2 <- tm_shape(d2_stars) + 
#  tm_raster(col.legend = tm_legend(title = "ALAN"))+ # use color legend
#   tm_graticules()+ # orienting
#   tm_title(text = "day 2 stars") # title
# 
# tmap_arrange(m1, m2, nrow = 1)
```

Scale factor

```{r}
# alan
# correct the data scale factor
# according to Suomi-NPP VIIRS Surface Reflectance User’s Guide table 3, we need to apply the scale factor
# sf = 0.001

# scale_factor <- 0.001
# 
# # make a function to multiply by scale and add the offset
# scale_function <- function(x) {
#   x * scale_factor
# }
# 
# # apply the function
# alan_d1s <- st_apply(d1_stars, MARGIN = c(1, 2), FUN = scale_function)
# alan_d2s <- st_apply(d2_stars, MARGIN = c(1, 2), FUN = scale_function)
# 
# # any NA's? let's sum together the na's
# global(is.na(alan_d1s), "sum", na.rm = TRUE) # 0 NA's
# global(is.na(alan_d2s), "sum", na.rm = TRUE) # 0 NA's
# 
# # summary stats, use global to avoid taking a subsample
# global(alan_d1s, fun = "min", na.rm = TRUE) # 0
# global(alan_d1s, fun = "max", na.rm = TRUE) # 65.535
# global(alan_d2s, fun = "min", na.rm = TRUE) # 0
# global(alan_d2s, fun = "max", na.rm = TRUE) # 65.535
# 
# # quick look
# plot(alan_d1s) # check it out
# plot(alan_d2s) # check it out
# 
# # struggling with the downsampling in tmap, not showing high values
# m1 <- tm_shape(alan_d1s) + # scaled dataset
#   tm_raster(col.legend = tm_legend(title = "ALAN"))+ # use color legend
#   tm_graticules()+ # orienting
#   tm_title(text = "day 1") # title
# 
# m2 <- tm_shape(alan_d2s) + # scaled dataset
#  tm_raster(col.legend = tm_legend(title = "ALAN"))+ # use color legend
#   tm_graticules()+ # orienting
#   tm_title(text = "day 2") # title
# 
# tmap_arrange(m1, m2, nrow = 1)
```

### roads explore & wrangle

This is a sf dataframe with lines of roads that intersect the Houston metropolitan area

```{r}
# road
class(road) # make sure it is an "sf" "data.frame"
colnames(road) # for fun what kind of data do we have here
unique(st_is_valid(road)) # true
unique(st_geometry_type(road)) # lines
st_crs(road) # check crs: WGS 84 

# exploratory vis
tm_shape(road) +
  tm_basemap("OpenStreetMap") + # orient
  tm_graticules()+ # orient
  tm_lines(col = "blue") + # my layer, make sure it is LINES
  tm_title("Exploratory map of Roads (roads in blue)") # title
```

### house explore & wrangle

This is a sf dataframe with polygons of houses in the Houston area

```{r}
# house
class(house) # make sure it is an "sf" "data.frame"
colnames(house) # for fun what kind of data do we have here
unique(st_is_valid(house)) # true, good
unique(st_geometry_type(house)) # multipolygon

# exploratory vis
house_exploratory <- tm_shape(house) +
  tm_basemap("OpenStreetMap") + # orient
  tm_graticules()+ # orient
  tm_polygons(col = "blue") + # my layer, make sure it is polygons
  tm_title("Exploratory map of house (layer in blue)") # title

house_exploratory 
```


### socioeconomic explore & wrangle

I have 2 data objects that I will need to explore and merge here: `geo_layer` and `income`! My overarching goal is to make one sf dataframe with geographic data and income data for each row. 

We will join on the geo_id

`left_join` instead of `st_join` because income is not spatially enabled using `st_transform`?




```{r}
# left join



# ensure same crs



```


Now that all the data are read in, time to clean and prep datasets



```{r}
# Make sure to check that these datasets have the same coordinate reference systems! If not, transform them to match.

# alan
st_crs(d1_stars) # "EPSG",4326
st_crs(d2_stars) # "EPSG",4326

# roads
st_crs(road) # WGS84; "EPSG" 4326

# house
st_crs(house) # WGS84; "EPSG" 4326
```

To complete complete the tasks of this assignment, you will need to break your analysis into the following key steps:

1. find locations that experienced a blackout by creating a mask
2. exclude highways from analysis
3. identify homes that experienced blackouts by combining the locations of homes and blackouts
4. identify the census tracts likely impacted by blackout

Tip: For improved computational efficiency and easier interoperability with sf, I recommend using the stars package for raster handling.

Tip: "Find the change" means do subtraction! Value for the 7th and value of 16th day.

# 1. Create blackout mask



## 1.1 difference raster

find the change in night lights intensity (presumably) caused by the storm
hint: this will require creating a raster object for each day (2021-02-07 and 2021-02-16) (done above)

feb 7 (no blackout aka more light) - feb 16 (blackout) > 200 (phrase as "a loss" but not neg values)

```{r}
# check extent
st_bbox(d1_stars)
st_bbox(d2_stars) # yay same

# subtraction "difference raster" and the boolean TRUE FALSE for > 200
diff_stars <- d1_stars - d2_stars > 200

# quick vis
# tm_shape(diff_stars) + 
#  tm_raster(col.legend = tm_legend(title = "ALAN"))+ # use color legend
#   tm_graticules()+ # orienting
#   tm_title(text = "difference with boolean") # title
```
# 1.2 reclassify difference

reclassify the difference raster, assuming that any location that experienced a drop of more than 200 nW cm-2sr-1 experienced a blackout

```{r}
# make an object to mask
diff_stars[diff_stars==FALSE] <- NA

# check it out
# tm_shape(diff_stars) + 
#  tm_raster(col.legend = tm_legend(title = "ALAN"))+ # use color legend
#   tm_graticules()+ # orienting
#   tm_title(text = "UNSCALED diff > 200") # title
```

## 1.3 vectorize the blackout mask

vectorize the blackout mask
hint: use `st_as_sf()` to convert from a raster to a vector and fix any invalid geometries with `st_make_valid()`

```{r}
diff_v <- st_as_sf(diff_stars) %>% 
  st_make_valid()

unique(st_is_valid(diff_v))
class(diff_v) # woohoo, its an sf dataframe
st_crs(diff_v) # "EPSG",4326 still, good
```

Now we have a vector difference mask!

## 1.5 crop blackout mask

crop (spatially subset) the blackout mask to the Houston area as defined by the following coordinates:
(-96.5, 29), (-96.5, 30.5), (-94.5, 30.5), (-94.5, 29)

`st_bbox` or `st_points`

Remember, st_bbox needs to be converted (vectorize) into layers with `st_as_sf`.

```{r}
crop_bbox <- st_bbox(c(
  xmin = -96.5,
  ymin = 29,
  xmax = -94.5,
  ymax = 30.5),
  crs = st_crs(diff_v))

class(crop_bbox) # bbox
crop <- st_as_sfc(crop_bbox) # gotta make it a layer
class(crop)

# check extent
st_bbox(crop) # woohoo

# quick vis
# tm_shape(crop) +
#  tm_borders(col = "red")+ # use color legend
#   tm_graticules()+ # orienting
#   tm_title(text = "crop") # title

## now crop the actual blackout mask
# gonna use brackets to subset
diff_crop <- diff_v[crop, ] # keep all rows that spatially intersect with the crop  
# check extent
st_bbox(diff_crop) # pretty darn close, I'll take it

# quick vis
# tm_shape(diff_crop) +
#   tm_polygons(col= "red") +
#   tm_basemap("OpenStreetMap") +
#   tm_graticules() + 
#   tm_title("cropped blackout mask quick vis")
```

## 1.6 re-project cropped dataset

re-project the cropped blackout dataset to EPSG:3083 (NAD83 / Texas Centric Albers Equal Area)

```{r}
# st_transform

diff_crop <- diff_crop %>% 
  st_transform("EPSG:3083")

st_crs(diff_crop) # EPSG:3083 yay!

```


# 2. Exclude highways from the cropped blackout mask

Tip: st_disjoin

exclude any locations within 200 meters of all highways in the Houston area

Lab notes: whats the difference between `st_disjoint` and `st_difference`? 

## 2.1 id close to highway

identify areas within 200m of all highways
hint: you may need to use `st_union`

Lab notes: `st_buffer` to get within 200m (remember to check units! Is it in meters? km? `st_crs$units`)

```{r}

```

next turn the highways and buffers into one with `st_union`

```{r}

```


## 2.2 blackouts AND away from highway

find areas that experienced blackouts that are further than 200m from a highway

We want things OUTSIDE the buffer layer, so use `st_disjoin` (or maybe `st_difference`, this will be like st_intersection which will return the areas that do not intersect. make sure to look at output). 

```{r}

```


# 3. Identify the number of homes likely impacted by blackouts

## 3.1 id overlap

identify homes that overlap with areas that experienced blackouts

overlapped with areas that are non-highway and experienced a blackout (most recent object). We want to use `st_within`  if we want to only include homes that were entirely blacked out. `st_intersect` will allow partially in the blackout to be included too. 

```{r}
# check crs, match most previous one

# overlap it


```


# 4. Identify the census tracts likely impacted by blackout

Join socioeconomic with houses 

Next we need to join the building data and socioecon data using `st_within` or similar to ensure we know which houses in the socioecon are impacted by blackout

```{r}

# id which homes experience blackouts

```

Now we do data wrangling to summarize median income by census tract

```{r}
# data wrangling

# did not experience blackouts: find that data
```

Now build pretty plot

a plot comparing the distributions of median household income for census tracts that did and did not experience blackouts

```{r}

```

# 5. Outputs

## 5.1

a set of maps comparing night light intensities before and after the first two storms

```{r}

```


## 5.2
a map of the homes in Houston that lost power (map)

```{r}

```

an estimate of the number of homes in Houston that lost power (number)

```{r}

```

## 5.3
a map of the census tracts in Houston that lost power

```{r}

```


## 5.4
a plot comparing the distributions of median household income for census tracts that did and did not experience blackouts

```{r}

```


## 5.5
a brief reflection (approx. 100 words) summarizing your results and discussing any limitations to this study








